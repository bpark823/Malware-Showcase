from html import parser
import requests
import csv
from bs4 import BeautifulSoup, SoupStrainer


category = ['drinking', 'food', 'restaurant', 'automobile', 'apparel', 
'technology', 'business', 'company', 'beauty', 'household', 'tours', 
'airlines', 'television-channels', 'financial', 'health-medicine', 
'education', 'campaign', 'uncategorized']
max_page = 20

output = "slogans.csv"
straining = SoupStrainer('p', class_='list-group-item-text')
def collect_data(cat, max_page):
    rows = []
    for cat in category:
        base_url = f"https://www.sloganlist.com/{cat}-slogans/"
        for p in range(0, max_page):
            if(p > 0):
                url = base_url + 'index_' + str(p) + '.html'
            data = requests.get(base_url).text
            soup = BeautifulSoup(data, 'html.parser')
            spoon = BeautifulSoup(data, 'html.parser', parse_only= straining)
            orgNames = soup.findAll('div', {'class':'list-group-item-heading'})
            orgSlogans = spoon.findAll('p', {'class':'list-group-item-text'})
            for i in range(0, len(orgSlogans)):
                content = [orgNames[i].contents[0].strip(), orgSlogans[i].contents[0].strip("-. ")]
                rows.append(content)
        print(rows)
    return rows

def print_data(data, output):
    with open(output, 'w', newline = '') as file:
        write = csv.writer(file)
        write.writerow(['Company', 'Slogan'])
        write.writerows(data)
    
if __name__ == '__main__':
    pass

collect_data(category, max_page)